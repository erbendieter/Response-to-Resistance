{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Crime Data\n",
    "\n",
    "Final project for DS1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the crime report data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brinaseidel/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (16,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "crimes2004_2018 = pd.read_csv(\"https://data.austintexas.gov/api/views/fdj4-gpfu/rows.csv?accessType=DOWNLOAD\", dtype={'Census Tract': object})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns - columns_largeset below is the simplification of the column i.e. replacing spaces with underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Incident Number', 'Highest Offense Description',\n",
      "       'Highest Offense Code', 'Family Violence', 'Occurred Date Time',\n",
      "       'Occurred Date', 'Occurred Time', 'Report Date Time', 'Report Date',\n",
      "       'Report Time', 'Location Type', 'Address', 'Zip Code',\n",
      "       'Council District', 'APD Sector', 'APD District', 'PRA', 'Census Tract',\n",
      "       'Clearance Status', 'Clearance Date', 'UCR Category',\n",
      "       'Category Description', 'X-coordinate', 'Y-coordinate', 'Latitude',\n",
      "       'Longitude', 'Location'],\n",
      "      dtype='object')\n",
      "['inc_number', 'high_off_desc', 'high_off_code', 'fam_viol', 'date_time', 'date', 'time', 'report_date_time', 'report_date', 'report_time', 'loc_t ype', 'address', 'zip_code', 'council_district', 'apd_sector', 'apd_district', 'pra', 'cen_tract', 'clr_status', 'clr_date', 'ucr', 'cat_desc', 'x_coord', 'y_coord', 'latitude', 'longtitude', 'location']\n"
     ]
    }
   ],
   "source": [
    "print(crimes2004_2018.columns)\n",
    "columns_largeset = ['inc_number', 'high_off_desc', 'high_off_code', 'fam_viol', 'date_time', 'date', 'time', 'report_date_time', 'report_date']\n",
    "columns2_largeset = ['report_time', 'loc_t ype', 'address', 'zip_code', 'council_district', 'apd_sector', 'apd_district', 'pra', 'cen_tract', 'clr_status', 'clr_date', 'ucr', 'cat_desc', 'x_coord', 'y_coord', 'latitude', 'longtitude', 'location']\n",
    "columns_largeset += columns2_largeset\n",
    "print(columns_largeset)\n",
    "crimes2004_2018.columns = columns_largeset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have resistance data for 2009 to 2016, so we will keep only the corresponding years of crime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(crimes2004_2018['inc_number'].astype(str))\n",
    "temp = [l[0:4] for l  in temp]\n",
    "crimes2004_2018['year']= np.array(temp)\n",
    "crimes2009_2016 = crimes2004_2018.loc[crimes2004_2018['year'].isin(['2009','2010', '2011', '2012', '2013', '2014', '2015', '2016'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1049909, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inc_number</th>\n",
       "      <th>high_off_desc</th>\n",
       "      <th>high_off_code</th>\n",
       "      <th>fam_viol</th>\n",
       "      <th>date_time</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>report_date_time</th>\n",
       "      <th>report_date</th>\n",
       "      <th>report_time</th>\n",
       "      <th>...</th>\n",
       "      <th>clr_status</th>\n",
       "      <th>clr_date</th>\n",
       "      <th>ucr</th>\n",
       "      <th>cat_desc</th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longtitude</th>\n",
       "      <th>location</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20145043640</td>\n",
       "      <td>VIOL OF PROTECTIVE ORDER</td>\n",
       "      <td>3009</td>\n",
       "      <td>N</td>\n",
       "      <td>10/01/2014 08:19:00 PM</td>\n",
       "      <td>10/01/2014</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>10/01/2014 08:19:00 PM</td>\n",
       "      <td>10/01/2014</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>10/15/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3130355.0</td>\n",
       "      <td>3130355.0</td>\n",
       "      <td>30.315506</td>\n",
       "      <td>-97.690678</td>\n",
       "      <td>(30.31550566, -97.69067834)</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20115047788</td>\n",
       "      <td>RUNAWAY CHILD</td>\n",
       "      <td>4100</td>\n",
       "      <td>N</td>\n",
       "      <td>10/11/2011 06:00:00 AM</td>\n",
       "      <td>10/11/2011</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10/11/2011 10:49:00 AM</td>\n",
       "      <td>10/11/2011</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>10/12/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3137779.0</td>\n",
       "      <td>3137779.0</td>\n",
       "      <td>30.319818</td>\n",
       "      <td>-97.667024</td>\n",
       "      <td>(30.31981803, -97.66702419)</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20112011254</td>\n",
       "      <td>VIOL CITY ORDINANCE - OTHER</td>\n",
       "      <td>3299</td>\n",
       "      <td>N</td>\n",
       "      <td>07/20/2011 05:05:00 PM</td>\n",
       "      <td>07/20/2011</td>\n",
       "      <td>1705.0</td>\n",
       "      <td>07/20/2011 05:05:00 PM</td>\n",
       "      <td>07/20/2011</td>\n",
       "      <td>1705.0</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>09/03/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3106719.0</td>\n",
       "      <td>3106719.0</td>\n",
       "      <td>30.266295</td>\n",
       "      <td>-97.766915</td>\n",
       "      <td>(30.26629453, -97.76691542)</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20145045267</td>\n",
       "      <td>BURGLARY OF VEHICLE</td>\n",
       "      <td>601</td>\n",
       "      <td>N</td>\n",
       "      <td>10/11/2014 05:00:00 PM</td>\n",
       "      <td>10/11/2014</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>10/12/2014 04:13:00 AM</td>\n",
       "      <td>10/12/2014</td>\n",
       "      <td>413.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>11/04/2014</td>\n",
       "      <td>23F</td>\n",
       "      <td>Theft</td>\n",
       "      <td>3115529.0</td>\n",
       "      <td>3115529.0</td>\n",
       "      <td>30.268006</td>\n",
       "      <td>-97.738955</td>\n",
       "      <td>(30.26800598, -97.73895531)</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013141039</td>\n",
       "      <td>AGG ROBBERY/DEADLY WEAPON</td>\n",
       "      <td>300</td>\n",
       "      <td>N</td>\n",
       "      <td>01/14/2013 03:16:00 PM</td>\n",
       "      <td>01/14/2013</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>01/14/2013 03:16:00 PM</td>\n",
       "      <td>01/14/2013</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>02/18/2013</td>\n",
       "      <td>120</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>3125085.0</td>\n",
       "      <td>3125085.0</td>\n",
       "      <td>30.314675</td>\n",
       "      <td>-97.707407</td>\n",
       "      <td>(30.31467502, -97.70740742)</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    inc_number                high_off_desc  high_off_code fam_viol  \\\n",
       "0  20145043640     VIOL OF PROTECTIVE ORDER           3009        N   \n",
       "1  20115047788                RUNAWAY CHILD           4100        N   \n",
       "3  20112011254  VIOL CITY ORDINANCE - OTHER           3299        N   \n",
       "6  20145045267          BURGLARY OF VEHICLE            601        N   \n",
       "7   2013141039    AGG ROBBERY/DEADLY WEAPON            300        N   \n",
       "\n",
       "                date_time        date    time        report_date_time  \\\n",
       "0  10/01/2014 08:19:00 PM  10/01/2014  2019.0  10/01/2014 08:19:00 PM   \n",
       "1  10/11/2011 06:00:00 AM  10/11/2011   600.0  10/11/2011 10:49:00 AM   \n",
       "3  07/20/2011 05:05:00 PM  07/20/2011  1705.0  07/20/2011 05:05:00 PM   \n",
       "6  10/11/2014 05:00:00 PM  10/11/2014  1700.0  10/12/2014 04:13:00 AM   \n",
       "7  01/14/2013 03:16:00 PM  01/14/2013  1516.0  01/14/2013 03:16:00 PM   \n",
       "\n",
       "  report_date  report_time  ...  clr_status    clr_date  ucr  cat_desc  \\\n",
       "0  10/01/2014       2019.0  ...           N  10/15/2014  NaN       NaN   \n",
       "1  10/11/2011       1049.0  ...           N  10/12/2011  NaN       NaN   \n",
       "3  07/20/2011       1705.0  ...           C  09/03/2011  NaN       NaN   \n",
       "6  10/12/2014        413.0  ...           N  11/04/2014  23F     Theft   \n",
       "7  01/14/2013       1516.0  ...           C  02/18/2013  120   Robbery   \n",
       "\n",
       "     x_coord    y_coord   latitude longtitude                     location  \\\n",
       "0  3130355.0  3130355.0  30.315506 -97.690678  (30.31550566, -97.69067834)   \n",
       "1  3137779.0  3137779.0  30.319818 -97.667024  (30.31981803, -97.66702419)   \n",
       "3  3106719.0  3106719.0  30.266295 -97.766915  (30.26629453, -97.76691542)   \n",
       "6  3115529.0  3115529.0  30.268006 -97.738955  (30.26800598, -97.73895531)   \n",
       "7  3125085.0  3125085.0  30.314675 -97.707407  (30.31467502, -97.70740742)   \n",
       "\n",
       "   year  \n",
       "0  2014  \n",
       "1  2011  \n",
       "3  2011  \n",
       "6  2014  \n",
       "7  2013  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(crimes2009_2016.shape)\n",
    "crimes2009_2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the resistance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resistance_09 = pd.read_csv(\"https://data.austintexas.gov/api/views/sc8s-w4ka/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_10 = pd.read_csv(\"https://data.austintexas.gov/api/views/q5ym-htjz/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_11 = pd.read_csv(\"https://data.austintexas.gov/api/views/jipa-v8m5/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_12 = pd.read_csv(\"https://data.austintexas.gov/api/views/bx9w-y5sd/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_13 = pd.read_csv(\"https://data.austintexas.gov/api/views/qxx9-6iwk/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_14 = pd.read_csv(\"https://data.austintexas.gov/api/views/vv43-e55n/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_15 = pd.read_csv(\"https://data.austintexas.gov/api/views/iydp-s2cf/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_16 = pd.read_csv(\"https://data.austintexas.gov/api/views/h8jq-pcz3/rows.csv?accessType=DOWNLOAD\").astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of these datasets have different colnames - here, we standardize them so that we can combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_resistance = ['rin', 'prim_key', 'date', 'time', 'address', 'area_command', 'nature_of_contact', 'reason_desc', 'r2r_level', 'master_sub_id', 'sub_sex']\n",
    "columns2_resistance = ['sub_race', 'sub_ethn', 'sub_cond_desc', 'sub_res', 'weapon_1', 'weapon_2', 'weapon_3', 'weapon_4', 'weapon_5', 'num_shots', 'sub_eff', 'eff_on_officer']\n",
    "columns3_resistance = ['off_org_desc', 'off_comm_date', 'off_years_service', 'x_coord', 'y_coord', 'council_district']\n",
    "columns_resistance += columns2_resistance + columns3_resistance\n",
    "resistance_09.columns = columns_resistance\n",
    "resistance_10.columns = columns_resistance\n",
    "resistance_11.columns = columns_resistance\n",
    "resistance_12.columns = columns_resistance\n",
    "resistance_13.columns = columns_resistance\n",
    "resistance_14.columns = columns_resistance\n",
    "resistance_15.columns = columns_resistance\n",
    "resistance_16.columns = columns_resistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the data for all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resistances = [resistance_09,resistance_10,resistance_11,resistance_12, resistance_13,resistance_14,resistance_15, resistance_16]\n",
    "resistance = pd.concat(resistances,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23218, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rin</th>\n",
       "      <th>prim_key</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>address</th>\n",
       "      <th>area_command</th>\n",
       "      <th>nature_of_contact</th>\n",
       "      <th>reason_desc</th>\n",
       "      <th>r2r_level</th>\n",
       "      <th>master_sub_id</th>\n",
       "      <th>...</th>\n",
       "      <th>weapon_5</th>\n",
       "      <th>num_shots</th>\n",
       "      <th>sub_eff</th>\n",
       "      <th>eff_on_officer</th>\n",
       "      <th>off_org_desc</th>\n",
       "      <th>off_comm_date</th>\n",
       "      <th>off_years_service</th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "      <th>council_district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19654</td>\n",
       "      <td>200910720</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "      <td></td>\n",
       "      <td>200 W 4TH ST</td>\n",
       "      <td>GE</td>\n",
       "      <td>VIEWED OFFENSE</td>\n",
       "      <td>NECESSARY TO EFFECT ARREST / DETENTION</td>\n",
       "      <td>3.0</td>\n",
       "      <td>305859998: 200910720</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>GEORGE 400 REG I PATROL</td>\n",
       "      <td>01/08/1993 12:00:00 AM</td>\n",
       "      <td>16</td>\n",
       "      <td>3113640</td>\n",
       "      <td>10070272</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19656</td>\n",
       "      <td>200910883</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "      <td>0330</td>\n",
       "      <td>6309 BURNS ST</td>\n",
       "      <td>ID</td>\n",
       "      <td>DISPATCHED CALL</td>\n",
       "      <td>NECESSARY TO DEFEND REPORTING OFFICER</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66128268: 200910883</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MINOR INJURY</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>BAKER 700 REG I PATROL</td>\n",
       "      <td>04/27/2007 12:00:00 AM</td>\n",
       "      <td>2</td>\n",
       "      <td>3120652</td>\n",
       "      <td>10093724</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19734</td>\n",
       "      <td>200910883</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "      <td></td>\n",
       "      <td>6309 BURNS ST</td>\n",
       "      <td>ID</td>\n",
       "      <td>DISPATCHED CALL</td>\n",
       "      <td>NECESSARY TO EFFECT ARREST / DETENTION</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66128268: 200910883</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MINOR INJURY</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>BAKER 700 REG I PATROL</td>\n",
       "      <td>06/20/2008 12:00:00 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>3120652</td>\n",
       "      <td>10093724</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19735</td>\n",
       "      <td>200911936</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "      <td>1640</td>\n",
       "      <td>6710 ARROYO SECO</td>\n",
       "      <td>ID</td>\n",
       "      <td>DISPATCHED CALL</td>\n",
       "      <td>OTHER (DOCUMENT IN SUPPLEMENT)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>219233449: 200911936</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>BAKER 300 REG I PATROL</td>\n",
       "      <td>06/18/2004 12:00:00 AM</td>\n",
       "      <td>5</td>\n",
       "      <td>3117560</td>\n",
       "      <td>10097233</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19736</td>\n",
       "      <td>200911936</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "      <td>1635</td>\n",
       "      <td>6710 ARROYO SECO</td>\n",
       "      <td>ID</td>\n",
       "      <td>DISPATCHED CALL</td>\n",
       "      <td>OTHER (DOCUMENT IN SUPPLEMENT)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>314316133: 200911936</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>BAKER 300 REG I PATROL</td>\n",
       "      <td>01/04/2008 12:00:00 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>3117560</td>\n",
       "      <td>10097233</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rin   prim_key                    date  time           address  \\\n",
       "0  19654  200910720  01/01/2009 12:00:00 AM            200 W 4TH ST   \n",
       "1  19656  200910883  01/01/2009 12:00:00 AM  0330     6309 BURNS ST   \n",
       "2  19734  200910883  01/01/2009 12:00:00 AM           6309 BURNS ST   \n",
       "3  19735  200911936  01/01/2009 12:00:00 AM  1640  6710 ARROYO SECO   \n",
       "4  19736  200911936  01/01/2009 12:00:00 AM  1635  6710 ARROYO SECO   \n",
       "\n",
       "  area_command nature_of_contact                             reason_desc  \\\n",
       "0           GE    VIEWED OFFENSE  NECESSARY TO EFFECT ARREST / DETENTION   \n",
       "1           ID   DISPATCHED CALL   NECESSARY TO DEFEND REPORTING OFFICER   \n",
       "2           ID   DISPATCHED CALL  NECESSARY TO EFFECT ARREST / DETENTION   \n",
       "3           ID   DISPATCHED CALL          OTHER (DOCUMENT IN SUPPLEMENT)   \n",
       "4           ID   DISPATCHED CALL          OTHER (DOCUMENT IN SUPPLEMENT)   \n",
       "\n",
       "  r2r_level         master_sub_id       ...        weapon_5 num_shots  \\\n",
       "0       3.0  305859998: 200910720       ...             nan       nan   \n",
       "1       2.0   66128268: 200910883       ...             nan       1.0   \n",
       "2       1.0   66128268: 200910883       ...             nan       0.0   \n",
       "3       3.0  219233449: 200911936       ...             nan       nan   \n",
       "4       3.0  314316133: 200911936       ...             nan       nan   \n",
       "\n",
       "                       sub_eff               eff_on_officer  \\\n",
       "0  NO COMPLAINT OF INJURY/PAIN  NO COMPLAINT OF INJURY/PAIN   \n",
       "1                 MINOR INJURY  NO COMPLAINT OF INJURY/PAIN   \n",
       "2                 MINOR INJURY  NO COMPLAINT OF INJURY/PAIN   \n",
       "3  NO COMPLAINT OF INJURY/PAIN  NO COMPLAINT OF INJURY/PAIN   \n",
       "4  NO COMPLAINT OF INJURY/PAIN  NO COMPLAINT OF INJURY/PAIN   \n",
       "\n",
       "              off_org_desc           off_comm_date off_years_service  x_coord  \\\n",
       "0  GEORGE 400 REG I PATROL  01/08/1993 12:00:00 AM                16  3113640   \n",
       "1   BAKER 700 REG I PATROL  04/27/2007 12:00:00 AM                 2  3120652   \n",
       "2   BAKER 700 REG I PATROL  06/20/2008 12:00:00 AM                 1  3120652   \n",
       "3   BAKER 300 REG I PATROL  06/18/2004 12:00:00 AM                 5  3117560   \n",
       "4   BAKER 300 REG I PATROL  01/04/2008 12:00:00 AM                 1  3117560   \n",
       "\n",
       "    y_coord council_district  \n",
       "0  10070272              9.0  \n",
       "1  10093724              4.0  \n",
       "2  10093724              4.0  \n",
       "3  10097233              7.0  \n",
       "4  10097233              7.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(resistance.shape)\n",
    "resistance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the resistance data with the crime data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the resistance data, each primary key (\"prim_key\") represents an incident, and each record is a single officer's report of that incident. This means that there are often multiple records per primary key. In order to merge one-to-one, we want only one record per primary key.\n",
    "\n",
    "First, we should determine which columns are at the report level and which are at the primary key level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 5626\n",
      "nature_of_contact 828\n",
      "reason_desc 2100\n",
      "r2r_level 685\n",
      "master_sub_id 1451\n",
      "sub_sex 461\n",
      "sub_race 406\n",
      "sub_ethn 460\n",
      "sub_cond_desc 1120\n",
      "sub_res 2910\n",
      "weapon_1 1989\n",
      "weapon_2 729\n",
      "weapon_3 110\n",
      "weapon_4 9\n",
      "weapon_5 1\n",
      "num_shots 1814\n",
      "sub_eff 2194\n",
      "eff_on_officer 1722\n",
      "off_org_desc 3419\n",
      "off_comm_date 8258\n",
      "off_years_service 7599\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique primary keys\n",
    "n_prim_key = len(resistance[\"prim_key\"].unique())\n",
    "\n",
    "# For each other column in the resistence dataset, check if the number of unique records in terms of the primary key i\n",
    "for col in resistance.columns[3:]:\n",
    "    n_col = len(resistance.groupby([\"prim_key\", col]))\n",
    "    if n_col != n_prim_key:\n",
    "        diff = n_col-n_prim_key\n",
    "        print(col, diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few of these variables that we might want to use as dependent variables, so we will clean them so that there is one value per primary key as follows:\n",
    "1. weapon_* --> a dummy marking whether any officer reported a weapon\n",
    "2. r2r_level -->  most severe r2r level (lower numbers = more severe resistance) reported by any officer\n",
    "3. number_of_shots --> dummy marking whether any officer reported a shot fired\n",
    "4. sub_eff --> whether any officer reported that a subject complained of pain/injury\n",
    "5. eff_on_officer --> whether any officer complained of pain/injury\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean weapon variables\n",
    "resistance[\"weapon\"] = 0\n",
    "for col in [\"weapon_1\", \"weapon_2\", \"weapon_3\", \"weapon_4\", \"weapon_5\"]:\n",
    "    resistance.loc[~resistance[col].isin([\"WEAPONLESS (PRESSURE POINTS/KICKS/HAND)\", \"-\", \"nan\"]), \"weapon\"] = 1 \n",
    "    # Note: nan is usually used to mark weapons 2-5, I think we can safely assume that it means no weapon\n",
    "# Show that we've correctly marked cases where any weapon was used\n",
    "#resistance[[\"weapon_1\", \"weapon_2\", \"weapon_3\", \"weapon_4\", \"weapon_5\", \"weapon\"]].head(20)\n",
    "#resistance.weapon.value_counts()\n",
    "# Mark the entire primary key as having a weapon used if any police officer reported it as such\n",
    "resistance[\"any_weapon\"] = resistance.groupby(['prim_key'])['weapon'].transform(max)\n",
    "\n",
    "# Clean r2r level \n",
    "resistance['r2r_level'] = resistance['r2r_level'].astype(float)\n",
    "resistance[\"max_r2r\"] = resistance.groupby(['prim_key'])['r2r_level'].transform(min) # Note: lower numbers = more severe resistance\n",
    "\n",
    "# Clean number of shots\n",
    "resistance[\"shot\"] = 0\n",
    "resistance.loc[resistance[\"num_shots\"]!=\"nan\", \"shot\"] = 1\n",
    "resistance[\"any_shot\"] = resistance.groupby(['prim_key'])['shot'].transform(max)\n",
    "\n",
    "# Clean subject complaint of pain/njury\n",
    "resistance[\"sub_complaint\"] = 0\n",
    "resistance.loc[~resistance[\"sub_eff\"].isin([\"NO COMPLAINT OF INJURY/PAIN\"]), \"sub_complaint\"] = 1\n",
    "resistance[\"any_sub_complaint\"] = resistance.groupby(['prim_key'])['sub_complaint'].transform(max)\n",
    "\n",
    "# Clean officer complaint of pain/njury\n",
    "resistance[\"off_complaint\"] = 0\n",
    "resistance.loc[~resistance[\"eff_on_officer\"].isin([\"NO COMPLAINT OF INJURY/PAIN\"]), \"off_complaint\"] = 1\n",
    "resistance[\"any_off_complaint\"] = resistance.groupby(['prim_key'])['off_complaint'].transform(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the columns of resistance that we want to use, and drop duplicates so that there is one observation per primary key instead of one obsercation per report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Keep only necessary columns\n",
    "resistance = resistance[[\"prim_key\", \"date\", \"address\",\n",
    "                         \"any_weapon\", \"max_r2r\", \"any_shot\", \"any_sub_complaint\", \"any_off_complaint\"]]\n",
    "\n",
    "# Drop duplicates\n",
    "resistance = resistance.drop_duplicates()\n",
    "\n",
    "# Confirm data is now unique by primary key\n",
    "print(len(resistance[\"prim_key\"].unique()) == resistance.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"prim_key\" in the resistance data appears similar to \"inc_number\" in the crime data, but sometimes these have different numbers of characters. However, by looking closely at one year of data, we found that the addresses do tend to match exactly for cases that have similar \"prim_key\" and \"inc_number\" values that are slightly different lengths. \n",
    "\n",
    "We therefore take the first six characters of \"inc_number\" and \"prim_key\", and merge on these values PLUS the address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_only     1036756\n",
       "both            13412\n",
       "right_only       1610\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes2009_2016[\"inc_number\"] = crimes2009_2016[\"inc_number\"].apply(str)\n",
    "crimes2009_2016[\"prim_key_short\"] = crimes2009_2016[\"inc_number\"].str[0:7]\n",
    "resistance[\"prim_key_short\"] = resistance[\"prim_key\"].str[0:7]\n",
    "combined = pd.merge(crimes2009_2016, resistance, how=\"outer\", on=[\"prim_key_short\", \"address\"], indicator=True)\n",
    "combined._merge.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect there to be a lot of \"left_only\" cases in the crime data that are not in the resistance data - these are all the cases where there was a crime but no resistance. \n",
    "\n",
    "However, we should be concerned about \"right_only\" cases where there was resistence to a crime, but that crime was not recorded in the full dataset. There are about 1,603 of these cases (and 13,420 merged correctly)\n",
    "\n",
    "Below, we look at some cases that didn't merge correctly and then drop them so that we can run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prim_key</th>\n",
       "      <th>date_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1050168</th>\n",
       "      <td>200910463</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050169</th>\n",
       "      <td>200911145</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050170</th>\n",
       "      <td>200920816</td>\n",
       "      <td>01/02/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050171</th>\n",
       "      <td>200971637</td>\n",
       "      <td>01/07/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050172</th>\n",
       "      <td>200982170</td>\n",
       "      <td>01/08/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          prim_key                  date_y\n",
       "1050168  200910463  01/01/2009 12:00:00 AM\n",
       "1050169  200911145  01/01/2009 12:00:00 AM\n",
       "1050170  200920816  01/02/2009 12:00:00 AM\n",
       "1050171  200971637  01/07/2009 12:00:00 AM\n",
       "1050172  200982170  01/08/2009 12:00:00 AM"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.loc[combined._merge == \"right_only\", [\"prim_key\", \"date_y\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.loc[combined._merge != \"right_only\", ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll create a dummy marking the cases that were in the resistance data has having had some sort of resistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1036756\n",
       "1      13412\n",
       "Name: any_resistance, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[\"any_resistance\"] = 0\n",
    "combined.loc[combined._merge == \"both\", \"any_resistance\"] = 1\n",
    "combined.drop(\"_merge\", axis=1, inplace=True)\n",
    "combined.any_resistance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the outcome variables\n",
    "\n",
    "We use two target variables - one measuring whether there was any resistance and one measuring whether there was any resistance where anyone (officer or subject) complained of pain/injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking types\n",
    "combined.dtypes\n",
    "\n",
    "#replacing NaN with zero\n",
    "outcome = ['any_weapon','max_r2r','any_shot','any_sub_complaint','any_off_complaint']\n",
    "combined[outcome] = combined[outcome].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create target variables\n",
    "combined['Target1'] = combined['any_resistance']\n",
    "combined['Target2'] = combined[['any_sub_complaint','any_off_complaint']].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge in weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the Austin weather; data set is from 2009-2016\n",
    "weather_data = pd.read_csv('Input Data/weather_09to16.csv')\n",
    "\n",
    "#re-format date from 'weather' to match the 'combined' DataFrame's date format\n",
    "weather_data['Date']= weather_data['Date'].str.replace('-', '/', regex=False)\n",
    "\n",
    "#merge in weather data\n",
    "combined = combined.join(weather_data.set_index('Date'), on='date_x')\n",
    "#combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare features based on when an incident occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge in US Holiday data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the US holidays from csv; data set is from 1966-2020\n",
    "us_holidays = pd.read_csv('Input Data/usholidays.csv')\n",
    "\n",
    "#creating a new column for each holiday that will show True or False for each day if it falls on that holiday\n",
    "us_holidays['new_year'] = (us_holidays['Holiday'] == \"New Year's Day\").astype(int)\n",
    "us_holidays['mlk_day'] = (us_holidays['Holiday'] == \"Birthday of Martin Luther King, Jr.\").astype(int)\n",
    "us_holidays['wash_bday'] = (us_holidays['Holiday'] == \"Washington's Birthday\").astype(int)\n",
    "us_holidays['mem_day'] = (us_holidays['Holiday'] == \"Memorial Day\").astype(int)\n",
    "us_holidays['ind_day'] = (us_holidays['Holiday'] == \"Independence Day\").astype(int)\n",
    "us_holidays['labor_day'] = (us_holidays['Holiday'] == \"Labor Day\").astype(int)\n",
    "us_holidays['col_day'] = (us_holidays['Holiday'] == \"Columbus Day\").astype(int)\n",
    "us_holidays['vet_day'] = (us_holidays['Holiday'] == \"Veterans Day\").astype(int)\n",
    "us_holidays['thanksgiving'] = (us_holidays['Holiday'] == \"Thanksgiving Day\").astype(int)\n",
    "us_holidays['christmas'] = (us_holidays['Holiday'] == \"Christmas Day\").astype(int)\n",
    "\n",
    "#re-format date from 'us_holidays' to match the 'combined' DataFrame's date format\n",
    "us_holidays['Date']= us_holidays['Date'].str.replace('-', '/', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the 'combined' and 'us_holidays' data frames on the date (date_x in 'combined', 'Date' in 'us_holidays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.join(us_holidays.set_index('Date'), on='date_x')\n",
    "\n",
    "#drop the unnecessary columns from the combined2 DataFrame (imported during join)\n",
    "combined.drop(['Unnamed: 0', 'Holiday'], axis = 1)\n",
    "\n",
    "#to 'fill' the combined  DataFrame, use slicing to select the columns from 'us_holidays' that need to be filled\n",
    "#fill combined DataFrame with 'False'\n",
    "#Essentially, we're saying that any day that doesn't match a US holiday should say 'False' in that columm\n",
    "j = list(us_holidays.columns)[3:]\n",
    "combined[j] = combined[j].fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare features based on date and time of the incident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing to date format\n",
    "combined['date_time'] = combined['date_time'].astype('datetime64[ns]')\n",
    "#combined['report_date_time'] = combined['report_date_time'].astype('datetime64[ns]') # Arushi - I commented this out because it was taking forever to run on my computer\n",
    "#combined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year\n",
    "combined['year'] = combined['date_time'].dt.year\n",
    "\n",
    "# Month\n",
    "combined['month'] = combined['date_time'].dt.month\n",
    "\n",
    "# Day of week \n",
    "combined['day_of_week'] = combined['date_time'].dt.dayofweek\n",
    "#Here, 0 is Monday, 1 is Tuesday, 2 is Wednesday and so on..\n",
    "\n",
    "# Hour of day\n",
    "combined['hour_of_day'] = combined['date_time'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models will need us to transform these continuous variables (1-12, 0-6, 0-23, etc.) into dummy variables for each possible hour of day, day of week, etc.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Months\n",
    "month_dummies = pd.get_dummies(combined.month)\n",
    "cols = []\n",
    "for col in month_dummies.columns:\n",
    "    cols.append(\"month\"+str(int(col)))\n",
    "month_dummies.columns = cols\n",
    "\n",
    "# Days of week\n",
    "day_dummies = pd.get_dummies(combined.day_of_week)\n",
    "cols = []\n",
    "for col in day_dummies.columns:\n",
    "    cols.append(\"day\"+str(int(col)))\n",
    "day_dummies.columns = cols\n",
    "\n",
    "# Hour of day\n",
    "hour_dummies = pd.get_dummies(combined.hour_of_day)\n",
    "cols = []\n",
    "for col in hour_dummies.columns:\n",
    "    cols.append(\"hour\"+str(int(col)))\n",
    "hour_dummies.columns = cols\n",
    "\n",
    "# Append to full dataset\n",
    "combined = pd.concat([combined, month_dummies, day_dummies, hour_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge in census data\n",
    "\n",
    "Census tract code for the two counties we care about should be six digits of the format 0ABCDE in order to merge with data from the Census API. We appear to have been something like the form BC.D, with leading/trailing zeroes dropped. Below, we clean the census tract data we were given to match the 0ABCDE format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split \n",
    "ct_split = combined[\"cen_tract\"].str.split(\".\", expand=True)\n",
    "combined[\"ct1\"] = ct_split[0]\n",
    "combined[\"ct2\"] = ct_split[1]\n",
    "\n",
    "# Calculate the length of each split piece - if the first is <4 digits, we add leading zeros, and if the second is <2 digits, we add trailing zeroes\n",
    "combined[\"ct1_len\"] = combined.ct1.str.len()\n",
    "combined[\"ct2_len\"] = combined.ct2.str.len()\n",
    "combined.loc[combined.ct2_len==1, \"ct2\"] = combined.loc[combined.ct2_len==1, \"ct2\"] + \"0\"\n",
    "combined.loc[combined.ct2_len.isnull() & (combined.ct1_len <=4), \"ct2\"] = \"00\"\n",
    "combined.loc[combined.ct1_len==1, \"ct1\"] = \"000\" + combined.loc[combined.ct1_len==1, \"ct1\"] \n",
    "combined.loc[combined.ct1_len==2, \"ct1\"] = \"00\" + combined.loc[combined.ct1_len==2, \"ct1\"] \n",
    "combined.loc[combined.ct1_len==3, \"ct1\"] = \"0\" + combined.loc[combined.ct1_len==3, \"ct1\"] \n",
    "\n",
    "combined[\"ct1_len\"] = combined.ct1.str.len()\n",
    "combined[\"ct2_len\"] = combined.ct2.str.len()\n",
    "\n",
    "# Examine cases where either piece is > 2 digits - should not be possible\n",
    "combined.loc[combined.ct1_len >4, \"cen_tract\"].value_counts()\n",
    "# These look like they're missing a decimal point. I'm just going to assume the last two characters go after the decimal point.\n",
    "# (It's only 11 cases anyway.)\n",
    "combined.loc[combined.ct1_len >4, \"ct1\"] = combined.loc[combined.ct1_len >4, \"cen_tract\"][:-2]\n",
    "combined.loc[combined.ct1_len >4, \"ct2\"] = combined.loc[combined.ct1_len >4, \"cen_tract\"][-2:]\n",
    "\n",
    "# Concatenate the two parts\n",
    "combined[\"tract\"] = combined.ct1 + combined.ct2\n",
    "\n",
    "combined.drop([\"cen_tract\",\"ct1\", \"ct1_len\", \"ct2\", \"ct2_len\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll pull some relevant indicators from the 2010 Census API. See full documentation of Table SF1 codes here: https://www.census.gov/prod/cen2010/doc/sf1.pdf.\n",
    "The indicators we are pulling are:\n",
    "- P0030001 - total population (which we will need for the denominator)\n",
    "- P0030002 - white population\n",
    "- P0030003 - black population\n",
    "- P0030004 - American Indian/native Alaskan population\n",
    "- P0030005 - Asian population \n",
    "- P0030006 - Hawaiian / Pacific Islander population\n",
    "- P0030007 - other race population\n",
    "- P0030008 - 2+ races population\n",
    "- P0040003 - Hispanic or Latino population (NOTE: not a race)\n",
    "- P0130001 - median age\n",
    "- P0130002 - median age for males\n",
    "- P0130003 - median age for females\n",
    "- P0180001 - total households (which we will need for the denominator)\n",
    "- P0200002 - households with any children under 18\n",
    "- P0250002 - households with any member over 65\n",
    "- P0190007 - households with husband-wife\n",
    "\n",
    "There are about 5723 cases that were missing census tract data in the original file. These (of course) did not merge with the census data from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"key\": \"7530e2501288a8dfb28803342f5d1493cf00cb96\",\n",
    "          \"state\": \"48\",   # Texas\n",
    "          \"county\": \"453,491\",  # Travis County, Williamson County\n",
    "          \"indicators\": \"P0030001,P0030002,P0030003,P0030004,P0030005,P0030006,P0030007,P0030008,P0040003,P0130001,P0130002,P0130003,P0180001,P0200002,P0250002,P0190007\"\n",
    "         }\n",
    "url = \"https://api.census.gov/data/2010/sf1?get=\"+params[\"indicators\"]+\"&for=tract:*&in=state:\"+params[\"state\"]+\"&in=county:\"+params[\"county\"]+\"&key=\"+params[\"key\"]\n",
    "response = requests.get(url, data = {'key':'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = pd.DataFrame(response.json()[1:])\n",
    "census_data.columns = response.json()[0]\n",
    "census_data.drop([\"state\", \"county\"], axis=1, inplace=True)\n",
    "combined = pd.merge(combined, census_data, how=\"outer\", on=\"tract\", indicator=True)\n",
    "combined._merge.value_counts()\n",
    "combined = combined.loc[combined._merge != \"right_only\", ]\n",
    "combined[\"has_census_data\"] = combined._merge == \"both\"\n",
    "combined.drop(\"_merge\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will calculate each indicator as percent of total population / percent of households."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"P0030001\",\"P0030002\",\"P0030003\",\"P0030004\",\"P0030005\",\"P0030006\",\"P0030007\",\"P0030008\",\"P0040003\",\"P0130001\",\"P0130002\",\"P0130003\", \"P0180001\",\"P0200002\",\"P0250002\",\"P0190007\"]:\n",
    "    combined[col] = combined[col].astype(float)\n",
    "    \n",
    "for col in [\"P0030002\",\"P0030003\",\"P0030004\",\"P0030005\",\"P0030006\",\"P0030007\",\"P0030008\",\"P0040003\"]:\n",
    "    combined[col+\"_pct\"] = combined[col]/combined[\"P0030001\"]\n",
    "\n",
    "for col in [\"P0200002\",\"P0250002\",\"P0190007\"]:\n",
    "    combined[col+\"_pct\"] = combined[col]/combined[\"P0180001\"]\n",
    "    \n",
    "combined.drop( [\"P0030002\",\"P0030003\",\"P0030004\",\"P0030005\",\"P0030006\",\"P0030007\",\"P0030008\", \"P0040003\", \"P0180001\",\"P0200002\",\"P0250002\",\"P0190007\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will also pull some data from the American Community Survey (ACS) 5-year estimates. We need to use the 5-year estimates in order to have data down to the tract level. The full list of available variables is here: https://api.census.gov/data/2016/acs/acs5/variables.html. The indicators we're using are:\n",
    "- B19113_001E - median family income in the past 12 months\n",
    "- B01001_001E - total population (which we will need for the denominator)\n",
    "- B17001_001E - poverty status in the past 12 months \n",
    "- C18120_002e - total labor force (which we will need for the denominator)\n",
    "- C18120_003E - total employed in the labor force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"key\": \"7530e2501288a8dfb28803342f5d1493cf00cb96\",\n",
    "          \"state\": \"48\",   # Texas\n",
    "          \"county\": \"453,491\",  # Travis County, Williamson County\n",
    "          \"indicators\": \"B01001_001E,B19113_001E,B17001_001E,C18120_002E,C18120_003E\"\n",
    "         }\n",
    "url = \"https://api.census.gov/data/2016/acs/acs5?get=\"+params[\"indicators\"]+\"&for=tract:*&in=state:\"+params[\"state\"]+\"&in=county:\"+params[\"county\"]+\"&key=\"+params[\"key\"]\n",
    "response = requests.get(url, data = {'key':'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_data = pd.DataFrame(response.json()[1:])\n",
    "acs_data.columns = response.json()[0]\n",
    "acs_data.drop([\"state\", \"county\"], axis=1, inplace=True)\n",
    "for col in ['B01001_001E','B19113_001E','B17001_001E','C18120_002E','C18120_003E']:\n",
    "    acs_data[col] = acs_data[col].astype(float)\n",
    "#Missing values are recorded as -666666666; must clean these.\n",
    "acs_data.B19113_001E.replace(-666666666, None, inplace=True)\n",
    "combined = pd.merge(combined, acs_data, how=\"outer\", on=\"tract\", indicator=True)\n",
    "combined._merge.value_counts()\n",
    "combined = combined.loc[combined._merge != \"right_only\", ]\n",
    "combined.drop(\"_merge\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will calculate each indicator as percent of the relevant population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"B17001_001E_pct\"] = combined.B17001_001E/combined.B01001_001E\n",
    "combined[\"C18120_003E_pct\"] = combined.C18120_003E/combined.C18120_002E\n",
    "\n",
    "combined.drop(['B01001_001E','B17001_001E','C18120_002E','C18120_003E'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['inc_number', 'high_off_desc', 'high_off_code', 'fam_viol', 'date_time',\n",
       "       'date_x', 'time', 'report_date_time', 'report_date', 'report_time',\n",
       "       ...\n",
       "       'P0030006_pct', 'P0030007_pct', 'P0030008_pct', 'P0040003_pct',\n",
       "       'P0200002_pct', 'P0250002_pct', 'P0190007_pct', 'B19113_001E',\n",
       "       'B17001_001E_pct', 'C18120_003E_pct'],\n",
       "      dtype='object', length=129)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop vars we don't need\n",
    "combined.drop([\"has_census_data\", \"Unnamed: 0\", \"inc_number\", \"high_off_desc\", \"high_off_code\", \"report_date_time\", \"report_date\",\n",
    "                   \"report_time\", \"address\", \"x_coord\", \"y_coord\", \"inc_number\", \"prim_key\", \"prim_key_short\", \n",
    "                   \"fam_viol\",\"address\", \"pra\", \"ucr\", \"clr_status\", \"clr_date\", \"cat_desc\", \"date_y\", \"Holiday\"], \n",
    "              axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined.to_csv('clean_data.csv',index=False)\n",
    "#combined.to_csv('../Personal Response_to_Resistance/Input Data/clean_data.csv',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
